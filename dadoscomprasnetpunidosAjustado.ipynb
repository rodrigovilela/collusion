{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jaydebeapi\n",
    "!pip install jpype1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo %JAVA_HOME%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import jaydebeapi\n",
    "import jpype\n",
    "import dateutil.parser\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "BASE_DIR = 'C:/Tools/serpro/'\n",
    "\n",
    "class DassDB:\n",
    "\n",
    "    conn = None\n",
    "    url = None\n",
    "    TEIID_JAR = 'jboss-dv-6.3.0-teiid-jdbc.jar'\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        self.connect()\n",
    "\n",
    "    def __del__(self):\n",
    "        try:\n",
    "            if self.conn:\n",
    "                self.conn.close()\n",
    "        except Exception as e:\n",
    "            logger.error(\"Erro fechar a conexão DAAS\")\n",
    "            logger.exception(e)\n",
    "            pass\n",
    "\n",
    "    def connect(self):\n",
    "        jar_path = os.path.join(BASE_DIR, DassDB.TEIID_JAR)\n",
    "        if not jpype.isJVMStarted():\n",
    "            # NOTE: after this PR is closed: https://github.com/baztian/jaydebeapi/pull/116\n",
    "            #      we can upgrade JayDeBeApi and remove this code\n",
    "            args = []\n",
    "            class_path = [jar_path]\n",
    "            class_path.extend(jaydebeapi._get_classpath())\n",
    "            args.append('-Djava.class.path=%s' % os.path.pathsep.join(class_path))\n",
    "            args.append('-Djavax.net.ssl.trustStore=%s' % os.path.join(BASE_DIR, 'daas.serpro.gov.br.jks'))\n",
    "            jvm_path = jpype.getDefaultJVMPath()\n",
    "            jpype.startJVM(jvm_path, *args)\n",
    "\n",
    "        self.conn = jaydebeapi.connect(\"org.teiid.jdbc.TeiidDriver\",\n",
    "                                  self.url,\n",
    "                                  [DAAS_DB_USER, DAAS_DB_PASS],\n",
    "                                  jar_path)\n",
    "\n",
    "    def query(self, sql):\n",
    "        try:\n",
    "            cursor = self.conn.cursor()\n",
    "            cursor.execute(sql)\n",
    "        except Exception as e:\n",
    "            logger.exception(e)\n",
    "            logger.error(\"Erro ao executar no DAAS: {}.\".format(sql))\n",
    "            self.connect()\n",
    "            cursor = self.conn.cursor()\n",
    "            cursor.execute(sql)\n",
    "        desc = cursor.description\n",
    "        registros = [dict(zip([str(col[0]) for col in desc], row)) for row in cursor.fetchall()]\n",
    "        cursor.close()\n",
    "        return registros    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path  \n",
    "from scipy.stats import uniform\n",
    "from scipy.stats import kstest\n",
    "from scipy.stats import lognorm\n",
    "\n",
    "#SCREENS\n",
    "def ks_test_of_function(array_data, function):\n",
    "    '''Calculate the function (uniform or lognorm) of array_data and then calculate Kolmogorov–Smirnov test'''\n",
    "\n",
    "    if function is 'uniform':\n",
    "        loc, scale = uniform.fit(array_data)\n",
    "        n = uniform(loc=loc, scale=scale)\n",
    "    elif function is 'lognorm':\n",
    "        s, loc, scale = lognorm.fit(array_data)\n",
    "        n = lognorm(s=s, loc=loc, scale=scale)\n",
    "    else: \n",
    "        return None\n",
    "    return kstest(array_data, n.cdf)[0]\n",
    "\n",
    "def calculate_screen_variables(df, screens, decimals=4):\n",
    "    ''' Calculate the defined screens variables of the dataframe (columns are Tender and Bid_value). By default, 4 decimals of accuracy '''\n",
    "\n",
    "    if 'CV' in screens:\n",
    "        # Calculate the coefficient of variation (CV)\n",
    "        mean_bid_value_by_tender = df.groupby(['Tender'])['Bid_value'].mean()\n",
    "        std_by_tender = df.groupby(['Tender'])['Bid_value'].std()\n",
    "        cv = pd.Series(std_by_tender / mean_bid_value_by_tender, name='CV').round(decimals=decimals)\n",
    "        res = df.merge(cv, how='inner', left_on='Tender', right_on='Tender', sort=False)\n",
    "        res.set_index(df.index,inplace=True)\n",
    "        df = res\n",
    "    if 'SPD' in screens:\n",
    "        # Calculate the spread (SPD)\n",
    "        max_bid_value_by_tender = df.groupby(['Tender'])['Bid_value'].max()\n",
    "        min_bid_value_by_tender = df.groupby(['Tender'])['Bid_value'].min()\n",
    "        spd = pd.Series((max_bid_value_by_tender - min_bid_value_by_tender) / min_bid_value_by_tender, name='SPD').round(decimals=decimals)\n",
    "        res = df.merge(spd, how='inner', left_on='Tender', right_on='Tender', sort=False)\n",
    "        res.set_index(df.index,inplace=True)\n",
    "        df = res\n",
    "    if 'DIFFP' in screens:    \n",
    "        # Calculate the differences between the two lowest bids is the percentage difference (DIFFP)\n",
    "        min_bid_value_by_tender = df.groupby(['Tender'])['Bid_value'].min()\n",
    "        df_without_duplicates = df.drop_duplicates(subset=['Bid_value'])\n",
    "        min2_bid_value_by_tender = df_without_duplicates.groupby(['Tender'])['Bid_value'].nsmallest(2).groupby(['Tender']).last()\n",
    "        diffp = pd.Series((min2_bid_value_by_tender - min_bid_value_by_tender) / min_bid_value_by_tender, name='DIFFP').round(decimals=decimals)\n",
    "        res = df.merge(diffp, how='inner', left_on='Tender', right_on='Tender', sort=False)\n",
    "        res.set_index(df.index,inplace=True)\n",
    "        df = res\n",
    "    if 'RD' in screens:\n",
    "        min_bid_value_by_tender = df.groupby(['Tender'])['Bid_value'].min()\n",
    "        std_by_tender = df.groupby(['Tender'])['Bid_value'].std()\n",
    "        df_without_duplicates = df.drop_duplicates(subset=['Bid_value'])\n",
    "        min2_bid_value_by_tender = df_without_duplicates.groupby(['Tender'])['Bid_value'].nsmallest(2).groupby(['Tender']).last()\n",
    "        df_max_bid_by_tenders = df.groupby(['Tender'])['Bid_value'].transform('max')\n",
    "        df_losing_bids = df[~(df['Bid_value'] == df_max_bid_by_tenders)]\n",
    "        std_losing_bids_by_tender = df_losing_bids.groupby(['Tender'])['Bid_value'].std()\n",
    "        df_std_losing_bids_by_tender = pd.DataFrame({'Tender': std_losing_bids_by_tender.index, 'STD': std_losing_bids_by_tender.values})\n",
    "        df_std_by_tender = pd.DataFrame({'Tender': std_by_tender.index, 'STD': std_by_tender.values})\n",
    "        #df_std_losing_bids_by_tender['STD'] = df_std_losing_bids_by_tender['STD'].replace(0, np.nan)\n",
    "        df_std_losing_bids_by_tender['STD'] = df_std_losing_bids_by_tender['STD'].fillna(df_std_by_tender['STD'])\n",
    "        std_losing_bids_by_tender =  pd.Series(data=df_std_losing_bids_by_tender['STD'])\n",
    "        rd = pd.Series((min2_bid_value_by_tender.reset_index(drop=True) - min_bid_value_by_tender.reset_index(drop=True)) / std_losing_bids_by_tender.reset_index(drop=True), name='RD')\n",
    "        rd = pd.DataFrame({'Tender': min_bid_value_by_tender.index, 'RD': rd.values}).round(decimals=decimals)\n",
    "        res = df.merge(rd, how='inner', left_on='Tender', right_on='Tender', sort=False)\n",
    "        res.set_index(df.index,inplace=True)\n",
    "        df = res\n",
    "    if 'KURT' in screens:\n",
    "        # Calculate Kurtosis statistic (KURTO)\n",
    "        kurtosis_by_tender = df.groupby(['Tender'])['Bid_value'].apply(pd.DataFrame.kurt)\n",
    "        kurtosis_by_tender = pd.Series(kurtosis_by_tender, name='KURT')\n",
    "        kurtosis_by_tender = kurtosis_by_tender.fillna(0).round(decimals=decimals)\n",
    "        res = df.merge(kurtosis_by_tender, how='inner', left_on='Tender', right_on='Tender', sort=False) \n",
    "        res.set_index(df.index,inplace=True)\n",
    "        df = res\n",
    "    if 'SKEW' in screens:    \n",
    "        # Calculate Kewness statistic (SKEW)\n",
    "        skew_by_tender = df.groupby(['Tender'])['Bid_value'].skew()\n",
    "        skew_by_tender = pd.Series(skew_by_tender, name='SKEW')\n",
    "        skew_by_tender = skew_by_tender.fillna(0).round(decimals=decimals)\n",
    "        res = df.merge(skew_by_tender, how='inner', left_on='Tender', right_on='Tender', sort=False)\n",
    "        res.set_index(df.index,inplace=True)\n",
    "        df = res\n",
    "    if 'KSTEST' in screens:\n",
    "        # Calculate Kolmogorov-Smirnov statistic (KSTEST) for verifying if the bids in a tender follow a distribution (uniform, lognorm, etc...)\n",
    "        kolmogorov_smirnov_by_tender = df.groupby(['Tender'])['Bid_value'].apply(lambda x: ks_test_of_function(x, 'uniform'))\n",
    "        kolmogorov_smirnov_by_tender = pd.Series(kolmogorov_smirnov_by_tender, name='KSTEST').round(decimals=decimals)\n",
    "        res = df.merge(kolmogorov_smirnov_by_tender, how='inner', left_on='Tender', right_on='Tender', sort=False)\n",
    "        res.set_index(df.index,inplace=True)\n",
    "        df = res\n",
    "    if 'KSTEST_L' in screens:\n",
    "        # Calculate Kolmogorov-Smirnov statistic (KSTEST) for verifying if the bids in a tender follow a distribution (uniform, lognorm, etc...)\n",
    "        kolmogorov_smirnov_by_tender = df.groupby(['Tender'])['Bid_value'].apply(lambda x: ks_test_of_function(x, 'lognorm'))\n",
    "        kolmogorov_smirnov_by_tender = pd.Series(kolmogorov_smirnov_by_tender, name='KSTEST_L').round(decimals=decimals)\n",
    "        res = df.merge(kolmogorov_smirnov_by_tender, how='inner', left_on='Tender', right_on='Tender', sort=False)\n",
    "        res.set_index(df.index,inplace=True)\n",
    "        df = res\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pathlib import Path  \n",
    "\n",
    "DAAS_COMPRASNET_DB_HOST = '' #Endereço DAAS do Comprasnet\n",
    "DAAS_SIASGNET_DB_HOST = '' #Endereço DAAS do SIASGNET\n",
    "DAAS_DB_USER = '' #Usuário DAAS\n",
    "DAAS_DB_PASS = '' #Senha DAAS\n",
    "db_comprasnet = DassDB(DAAS_COMPRASNET_DB_HOST)\n",
    "db_siasgnet = DassDB(DAAS_SIASGNET_DB_HOST)\n",
    "\n",
    "#Dataframe com todos os itens das licitações\n",
    "dfi = None\n",
    "#Arquivos csv com o dataframe\n",
    "nome_arquivo = 'C:/tmp/brazilian_comprasnet.csv'\n",
    "\n",
    "punidos = ['02293852000140', '01785999000194', '96355946000140', '35596501000167', '03187742000166', '62436282000121', '88309620000158', '01478038000137', \n",
    "           '07386939000185', '11572018000184', '04717562000101', '04809827000100', '06332079000134', '25181298000104', '01140694000125', '08859696000118', \n",
    "           '37517158000143', '03737267000154', '13385812000144', '02845074000154', '49254634000160', '44164606000138', '14744743000180', '02332985000188']\n",
    "\n",
    "if os.path.isfile(nome_arquivo):\n",
    "    dfi = pd.read_csv(nome_arquivo, index_col='Bid');\n",
    "    #dfi = pd.read_csv(nome_arquivo);\n",
    "else:    \n",
    "    #QTD_ADQUIRIDA\n",
    "    itens = db_comprasnet.query(\"SELECT p.prgCod, p.numprp, p.coduasg, pri.ipgCod, l.lanCod, pro.prpCNPJ, l.lanValor, \" +\n",
    "                                \" (case when l.lanValor = pri.ipgValorMinClassif then 1 else 0 end) as Winner, l.lanData, \" + \n",
    "                                \" pri.ipgValorRef, (pri.ipgValorRef - l.lanValor) as Difference_Bid_PTE, \" +\n",
    "                                \" pri.ipgValorMinClassif, pri.ipgQuantidade, pri.prgCod, pri.ipgItem, pri.codmat \" +\n",
    "                                \" FROM Comprasnet_VBL.tbl_Pregao p \" +\n",
    "                                \" INNER JOIN Comprasnet_VBL.tbl_pregaoitem pri ON p.prgCod = pri.prgCod \" +\n",
    "                                \" INNER JOIN Comprasnet_VBL.tbl_Lances l ON pri.ipgCod = l.ipgCod \" +\n",
    "                                \" INNER JOIN Comprasnet_VBL.tbl_Proposta pro ON pro.prgCod = pri.prgCod AND pro.Cliente_ID = l.cliente_id \" +                                \n",
    "                                \" WHERE pri.prgCod in (SELECT distinct proi.prgCod FROM Comprasnet_VBL.tbl_Proposta proi \" +\n",
    "                                \" WHERE proi.prpCNPJ in ('02293852000140', '01785999000194', '96355946000140', '35596501000167', '03187742000166', '62436282000121', '88309620000158', \" +\n",
    "                                \" '01478038000137', '07386939000185', '11572018000184', '04717562000101', '04809827000100', '06332079000134', '25181298000104', '01140694000125', \" +\n",
    "                                \" '08859696000118', '37517158000143', '03737267000154', '13385812000144', '02845074000154', '49254634000160', '44164606000138', '14744743000180', \" +\n",
    "                                \" '02332985000188')) \" +\n",
    "                                \" and ipgQuantidade > 0 \" +\n",
    "                                \" and l.lanStatus = 'V' \" +                                \n",
    "                                \" and pri.ipgFormaJulg = 'V' \" +\n",
    "                                \" and pri.ipgValorMinClassif is not null \" +\n",
    "                                \" order by pri.ipgCod, pri.ipgItem, l.lanValor \")\n",
    "    #print('itens:')\n",
    "    #print(itens)\n",
    "\n",
    "    #forçando conversão de campos texto\n",
    "    for item in itens:\n",
    "        #print('Item {}: {} - (Valor: {} - Min: {})'.format(item['ipgCod'],item['ipgItem'],item['lanValor'],item['ipgValorMinClassif']))\n",
    "        item['prpCNPJ'] = str(item['prpCNPJ'])\n",
    "        item['lanData'] = int(dateutil.parser.parse(item['lanData'], yearfirst=True).timestamp())\n",
    "        item['lanValor'] = round(item['lanValor'],4)\n",
    "        item['ipgValorMinClassif'] = round(item['ipgValorMinClassif'],4)\n",
    "        item['Difference_Bid_PTE'] = round(item['Difference_Bid_PTE'],4)\n",
    "    \n",
    "    dfi = json_normalize(itens)\n",
    "    dfi = dfi.rename(columns={'ipgCod': 'Tender', \n",
    "                             'lanCod': 'Bid', \n",
    "                             'prpCNPJ': 'Competitor', \n",
    "                             'lanValor': 'Bid_value', \n",
    "                             'lanData': 'Date', \n",
    "                             'ipgValorRef': 'Pre_Tender'})\n",
    "    dfi.set_index('Bid', inplace=True)\n",
    "    \n",
    "    dfi['atualizado'] = 0\n",
    "    dfi['Number_bids'] = 0\n",
    "    dfi['especificidade'] = 0\n",
    "    dfi['frequencia'] = 0\n",
    "    dfi['material'] = ' '\n",
    "    dfi['Collusive_competitor_original'] = 0\n",
    "    dfi['Collusive_competitor'] = 0\n",
    "\n",
    "    filepath = Path(nome_arquivo)  \n",
    "    filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "    dfi.to_csv(filepath) \n",
    "\n",
    "prgCod = None\n",
    "lances          = []\n",
    "especificidades = []\n",
    "frequencias     = []\n",
    "materiais       = []\n",
    "colusivo = 0\n",
    "licitacoes = 0\n",
    "\n",
    "for index, item in dfi.iterrows():\n",
    "    #print('Item {}: {} - ({}){}'.format(item['ipgCod'],item['ipgQuantidade'],item['prpCNPJ'],item['prpRazaoSocial']))\n",
    "\n",
    "    #Salta os registros atualizados\n",
    "    if item['atualizado'] == 1:\n",
    "        continue\n",
    "        \n",
    "    #encontrou novo pregão\n",
    "    if item['prgCod'] != prgCod:\n",
    "        prgCod = item['prgCod']\n",
    "        print('LICITACAO: {}'.format(prgCod))\n",
    "\n",
    "        #QTD_LANCES\n",
    "        lances = db_comprasnet.query(\"SELECT pri.ipgCod, count(l.ipgCod) as qtdeLances \" +\n",
    "                                     \" FROM Comprasnet_VBL.tbl_pregaoitem pri \" +\n",
    "                                     \" INNER JOIN Comprasnet_VBL.tbl_Lances l ON pri.ipgCod = l.ipgCod \" +\n",
    "                                    \" WHERE pri.prgCod = \" + str(prgCod) +\n",
    "                                    \" AND l.lanStatus = 'V' \" +\n",
    "                                    \" GROUP BY pri.ipgCod \")\n",
    "        #print('lances:')\n",
    "        #print(lances)\n",
    "\n",
    "\n",
    "        #ESPECIFICIDADE   \n",
    "        especificidades = db_comprasnet.query(\"SELECT pri.codmat, count(1) as especificidade \" +\n",
    "                                     \" FROM Comprasnet_VBL.tbl_pregaoitem pri \" +\n",
    "                                     \" INNER JOIN Comprasnet_VBL.tbl_pregaoitem prif ON pri.codmat = prif.codmat and prif.ipgCod != pri.ipgCod \" +\n",
    "                                    \" WHERE pri.prgCod = \" + str(prgCod) +\n",
    "                                    \" GROUP BY pri.codmat \")\n",
    "        #print('especificidades:')\n",
    "        #print(especificidades)\n",
    "\n",
    "\n",
    "        #FREQUENCIA\n",
    "        frequencias = db_comprasnet.query(\"SELECT prif.codmat, count(1) as frequencia \" +\n",
    "                                     \" FROM Comprasnet_VBL.tbl_pregaoitem pri \" +\n",
    "                                     \" INNER JOIN Comprasnet_VBL.tbl_propostaitem ppi ON pri.ipgCod = ppi.ipgCod and ppi.ippIndAdjudicado = 'S' \" +\n",
    "                                     \" INNER JOIN Comprasnet_VBL.tbl_proposta pp ON pp.prpCod = ppi.prpCod \" + \n",
    "                                     \" INNER JOIN Comprasnet_VBL.tbl_pregaoitem prif ON pri.codmat = prif.codmat and prif.ipgCod != pri.ipgCod \" +\n",
    "                                     \" INNER JOIN Comprasnet_VBL.tbl_propostaitem ppif ON prif.ipgCod = ppif.ipgCod and ppif.ippIndAdjudicado = 'S' \" +\n",
    "                                     \" INNER JOIN Comprasnet_VBL.tbl_proposta ppf ON ppf.prpCod = ppif.prpCod and pp.prpCNPJ = ppf.prpCNPJ \" +\n",
    "                                    \" WHERE pri.prgCod = \" + str(prgCod) +\n",
    "                                    \" GROUP BY prif.codmat \")\n",
    "        #print('frequencias:')\n",
    "        #print(frequencias)\n",
    "\n",
    "        #MATERIAL\n",
    "        materiais = db_siasgnet.query(\"SELECT distinct ic.numeroitem, ic.codigoitemcatalogo \" +\n",
    "                                    \" FROM Siasgnet_dc_Compartilhado_VBL.itemcompra ic \" +\n",
    "                                    \" JOIN Siasgnet_dc_Compartilhado_VBL.versaocompraitemcompra vci ON vci.codigoitemcompra = ic.codigoitemcompra \" +\n",
    "                                    \" JOIN Siasgnet_dc_Compartilhado_VBL.versaocompra vc ON vc.codigoversaocompra = vci.codigoversaocompra \" +\n",
    "                                    \" JOIN Siasgnet_dc_Compartilhado_VBL.compra c ON c.codigocompra = vc.codigocompra \" +\n",
    "                                    \" WHERE c.codigomodalidadecompra||c.numerouasgorigem||CAST(c.numerocompra AS INTEGER)||c.anocompra = 5\" + str(item['coduasg']) + str(item['numprp']) +\n",
    "                                    \" ORDER BY ic.numeroitem \")\n",
    "        #print('materiais de:'+ '5' + str(item['coduasg']) + str(item['numprp']))\n",
    "        #print(materiais)\n",
    "            \n",
    "        licitacoes = licitacoes + 1\n",
    "        \n",
    "        if (licitacoes % 100) == 0:\n",
    "            #Atualiza o arquivo a cada 100 pregões processados\n",
    "            filepath = Path('C:/tmp/brazilian_comprasnet.csv')  \n",
    "            filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "            dfi.to_csv(filepath) \n",
    "    \n",
    "    # Lance é de empresa punida se estiver entre CNPJs punidos\n",
    "    if str(item['Competitor']) in punidos:\n",
    "        dfi.at[index,'Collusive_competitor_original'] = 1\n",
    "        dfi.at[index,'Collusive_competitor'] = 1\n",
    "\n",
    "    for lance in lances:\n",
    "        if lance['ipgCod'] == item['Tender']:\n",
    "            dfi.at[index,'Number_bids'] = lance['qtdeLances']\n",
    "            break\n",
    "\n",
    "    for especificidade in especificidades:\n",
    "        if especificidade['codmat'] == item['codmat']:\n",
    "            dfi.at[index,'especificidade'] = especificidade['especificidade']\n",
    "            break\n",
    "\n",
    "    for frequencia in frequencias:\n",
    "        if frequencia['codmat'] == item['codmat']:\n",
    "            dfi.at[index,'frequencia'] = frequencia['frequencia']\n",
    "            break\n",
    "\n",
    "    for material in materiais:\n",
    "        if material['numeroitem'] == item['ipgItem']:\n",
    "            dfi.at[index,'material'] = str(material['codigoitemcatalogo'])\n",
    "            break\n",
    "\n",
    "    dfi.at[index,'atualizado'] = 1\n",
    "\n",
    "dfi.info()\n",
    "    \n",
    "#Calcula as screens\n",
    "screens = ['CV', 'SPD', 'DIFFP', 'RD', 'KURT', 'SKEW', 'KSTEST']\n",
    "dfi = calculate_screen_variables(dfi, screens)\n",
    "for screen in screens:\n",
    "    dfi[screen].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    dfi[screen] = dfi[screen].fillna(0)\n",
    "\n",
    "dfi.info()\n",
    "\n",
    "#Atualiza arquivo ao final\n",
    "filepath = Path(nome_arquivo)  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "dfi.to_csv(filepath) \n",
    "    \n",
    "dfi.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfi.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
